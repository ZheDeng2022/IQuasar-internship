<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on November 19, 2021</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04662983</url>
  </required_header>
  <id_info>
    <org_study_id>OpoleUofTech3</org_study_id>
    <nct_id>NCT04662983</nct_id>
  </id_info>
  <brief_title>Effects of Immersive Virtual Reality Traning on an Eye-hand Coordination and Time Reaction</brief_title>
  <official_title>Evaluation of the Effects of Immersive Virtual Reality Training on an Eye-hand Coordination and Central Executive Functioning in Young Musicians</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>The Opole University of Technology</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>The Opole University of Technology</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      Virtual reality (VR) is a three-dimensional image, which is created by means of computer&#xD;
      programs. In most educational communities VR has been used as an opportunity to support many&#xD;
      students. VR allows the user to observe the world generated for their own needs as the real&#xD;
      world and experience impressions that are not available in real life. It was decided to&#xD;
      examine how immersive VR-game will affect the eye-hand coordination on music school students.&#xD;
      The experimental group received a five-day training sessions using immersive VR game &quot;Beat&#xD;
      Saber&quot;, while control group was inactive comparator.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Eye-hand coordination can be defined as the ability to perform activities that require the&#xD;
      simultaneous use of eyes and hands. Eye-hand coordination supports our daily activities,&#xD;
      interactions with objects and people, and is critical to understanding how the brain creates&#xD;
      internal models of the space and generates movement within it (2). The eye-hand coordination&#xD;
      represents the integration of visual information, perceptual stimuli and motor decisions in&#xD;
      order to perform a specific task. Along with the development of technology, opportunities for&#xD;
      stimulation of eye-hand coordination with the use of technical novelties have appeared.&#xD;
      Virtual reality (VR) is a three-dimensional image, which is created by means of computer&#xD;
      programs. It has become one of the technologies that offer many possibilities of application&#xD;
      and use of its various aspects that can bring great benefits in the real world. In most&#xD;
      educational communities VR has been used as an opportunity to support many students. VR&#xD;
      allows the user to observe the world generated for their own needs as the real world and&#xD;
      experience impressions that are not available in real life. It can be assumed that VR can&#xD;
      help trainers or teachers, especially music teachers, by interacting through movement,&#xD;
      realization and graphic images, to develop and shape skills such as eye to hand coordination.&#xD;
      The use of virtual reality gives a wide range of possibilities for training, so it was&#xD;
      decided to examine how it will affect the coordination of the eye-hand response in music&#xD;
      school students.&#xD;
&#xD;
      The aim of the research was to evaluate the eye-hand coordination of music school students&#xD;
      undergoing training sessions in the musical game &quot;Beat Saber&quot; conducted in immersive virtual&#xD;
      reality.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Completed</overall_status>
  <start_date type="Actual">November 23, 2020</start_date>
  <completion_date type="Actual">December 16, 2020</completion_date>
  <primary_completion_date type="Actual">December 11, 2020</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Treatment</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Trail Making Test</measure>
    <time_frame>up to 5 days</time_frame>
    <description>Trial Making Test (TMT) A and TMT B were used to assess coordination. This test is a clinical tool for assessing eye-hand coordination. The task of the person tested in the first part (TMT A) was to combine 25 fields in order from the smallest to the largest continuous line. In the second part (TMT B), the subject was to alternate the numbers with the letters of the alphabet according to the formula 1-A, 2-B, 3-C, etc. with a continuous line. The result of the test is the time when the tested person connected all fields in the right order.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Plate Tapping Test</measure>
    <time_frame>up to 5 days</time_frame>
    <description>The Plate Tapping Test (Reaction Tap Test) is a reaction test using an alternating wall tapping action which measures upper body reaction time, hand-eye quickness and coordination. This test is part of the Eurofit Testing Battery.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>The ruler-drop test (Ditrich's test)</measure>
    <time_frame>up to 5 days</time_frame>
    <description>During the test, the tester sat on the chair face to face, on the with which he supported his forearm (in the middle of the length). The four fingers of the hand of the examined person were tight and the thumb was visited. The tester held a rod with a diameter of 1.5 cm and length of 50 cm, on which was marked with a centimeter scale. The task of the examined person was to react as quickly as possible to her movement and by clenching the hand grip sticks. The distance from the beginning was measured scale to the point of grasp (bottom edge hands).</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Energy expenditure</measure>
    <time_frame>up to 5 days</time_frame>
    <description>The SenseWear Armband was used to assess energy expenditure. The device was placed on the arm of the dominant upper limb. It continuously measured physiological variables through algorithms which determined the number of steps, MET, energy expenditure, and kcal</description>
  </secondary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Actual">14</enrollment>
  <condition>Virtual Reality</condition>
  <condition>Coordination Impairment</condition>
  <arm_group>
    <arm_group_label>Experimental group</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>The participants were subjected to a 15-minute training session, once a day for 5 consecutive days. HTC VIVE Pro (HTC Corporation, New Taipei, Taiwan) goggles and accessories were used. It is specialized equipment consisting of a high-resolution screen goggles and headphones, using an Intel WiGig Wireless connection, and the technology allows for free 360 degrees of movement. The interaction in virtual reality is performed using two controllers held by the player. The movement of the controllers and goggles is tracked by two sensors. The game area covered about 5m2, in the form of a rectangle, determined by the location of motion sensors, as recommended by the manufacturer. The participant received visual information when approaching the boundaries of the game field. A Beat Saber music game was used to conduct training sessions.</description>
  </arm_group>
  <intervention>
    <intervention_type>Device</intervention_type>
    <intervention_name>VR-training</intervention_name>
    <description>A musical game called Beat Saber was used to conduct training sessions. The participant's task was to cut through the blocks of various colors in his direction to the rhythm of music, using two virtual swords. The swords were controlled by the player with controllers of different colors. Blocks had to be cut with a sword whose color matches the block and in the right direction which is indicated by an arrow on the block. The training session consisted of 4 music tracks with different pace and intensity of objects. In addition, during the song, the participant had to avoid objects-objects that randomly appeared in the game scenario - forcing the whole body to move.</description>
    <arm_group_label>Experimental group</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
          -  acceptance to participate in the research,&#xD;
&#xD;
          -  age 14-24&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
          -  diagnosed neurological diseases,&#xD;
&#xD;
          -  fear of restricted vision or putting on goggles,&#xD;
&#xD;
          -  diagnosed musculoskeletal diseases,&#xD;
&#xD;
          -  injuries to the musculoskeletal system,&#xD;
&#xD;
          -  regular sports activities during the week.&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>14 Years</minimum_age>
    <maximum_age>24 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Sebastian Rutkowski, PhD</last_name>
    <role>Principal Investigator</role>
    <affiliation>The Opole University of Technology</affiliation>
  </overall_official>
  <location>
    <facility>
      <name>Faculty of Physical Education and Physiotherapy, Opole University of Technology</name>
      <address>
        <city>Opole</city>
        <zip>45-758</zip>
        <country>Poland</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>Poland</country>
  </location_countries>
  <verification_date>December 2020</verification_date>
  <study_first_submitted>November 14, 2020</study_first_submitted>
  <study_first_submitted_qc>December 9, 2020</study_first_submitted_qc>
  <study_first_posted type="Actual">December 10, 2020</study_first_posted>
  <last_update_submitted>December 16, 2020</last_update_submitted>
  <last_update_submitted_qc>December 16, 2020</last_update_submitted_qc>
  <last_update_posted type="Actual">December 17, 2020</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <keyword>virtual reality</keyword>
  <keyword>VR</keyword>
  <keyword>eye-hand coordination</keyword>
  <keyword>exergame</keyword>
  <keyword>energy expenditure</keyword>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Ataxia</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>Yes</sharing_ipd>
    <ipd_description>It was decided to provide free access to the analysed data. The data will be available upon request sent to PI: s.rutkowski@po.opole.pl.</ipd_description>
    <ipd_info_type>Study Protocol</ipd_info_type>
    <ipd_time_frame>6 months</ipd_time_frame>
    <ipd_access_criteria>The data will be available upon request sent to PI</ipd_access_criteria>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

