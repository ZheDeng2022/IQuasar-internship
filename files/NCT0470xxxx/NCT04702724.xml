<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on November 19, 2021</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04702724</url>
  </required_header>
  <id_info>
    <org_study_id>STU00213443-B</org_study_id>
    <nct_id>NCT04702724</nct_id>
  </id_info>
  <brief_title>Reinstatement of Context During Sleep and Its Subsequent Effect on Memory: an fMRI Study</brief_title>
  <official_title>The Role of Context in Sleep-related Memory Reactivation in Humans: Reinstatement of Temporal Context During Sleep and Its Subsequent Effect on Memory</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>Northwestern University</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>Northwestern University</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      Memory benefits from sleep and these benefits are putatively achieved through reactivation of&#xD;
      the neural memory trace during sleep. Studies examining the effects of reactivation commonly&#xD;
      focus on single, isolated items - but real-life memories never exist in a vacuum. Individual&#xD;
      memories are bound to the context (e.g., the location, time and state of mind in which they&#xD;
      are encoded) and this context is later reinstated to recall the details related to the&#xD;
      memory. The question of how context participated in the process of sleep reactivation has&#xD;
      never been directly examined. This experiment will monitor brain activity during memory&#xD;
      encoding, sleep and finally retrieval to investigate the role context plays in sleep-related&#xD;
      memory consolidation. Monitoring will be done using functional magnetic resonance imaging&#xD;
      (fMRI) and electroencephalographic (EEG) recordings. Participants will go through a series of&#xD;
      training trials, in which they will have to learn to associate several small images of items&#xD;
      or animals with a larger image of scenes - and also learn the spatial location of these&#xD;
      smaller images on the screen. The order of the presented images and the scenes in which they&#xD;
      are embedded will remain constant throughout training, creating a solid, consistent temporal&#xD;
      context in which item memories will be embedded. After training, participants will receive a&#xD;
      90 minute nap opportunity, during which the sounds associated with specific images will be&#xD;
      unobtrusively presented. I expect memory for the spatial location of the cued images to&#xD;
      improve. Importantly, I hypothesize that this effect will carry over to other items&#xD;
      associated with the same scene (i.e., embedded in the same context) and that the temporal&#xD;
      order in which the images were learned will govern this effect. I will use the EEG and fMRI&#xD;
      data to estimate, on the basis of neuronal pattern activity, the level of contextual&#xD;
      reinstatement and will build on these data, in combination with the behavioral results, to&#xD;
      model the level of contextual involvement during sleep. These results could pave the way&#xD;
      towards a unified theory of sleep's role in memory consolidation, which would encompass&#xD;
      computational models of context and memory as well.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Each participant will be run in a single afternoon, which includes a 90-minute nap&#xD;
      opportunity. This study will be divided into three continuous sessions. The first and third&#xD;
      sessions will be done inside the MRI scanner, whereas the middle session will be conducted&#xD;
      outside of the scanner, while recording electrophysiological data. The crucial manipulation&#xD;
      involves the careful control of temporal context, which is accomplished by preserving the&#xD;
      temporal order of trials during training and using spatial scenes as markers of context.&#xD;
&#xD;
      This is a within-subjects study. The main manipulation is the unobtrusive presentation of&#xD;
      sounds during sleep, a technique called targeted memory reactivation (TMR). All participants&#xD;
      will hear these sounds, but the specific sounds each one will hear will be different. The&#xD;
      results will then be compared within participant, not between different groups or&#xD;
      individuals. Appropriate statistical methods for such analyses include paired t-test and&#xD;
      repeated measures analysis of variance. The choice of which sounds will be presented to each&#xD;
      participant will be made based on their performance in the pre-sleep test. This will be done&#xD;
      in an attempt to balance pre-sleep scores between presented and unpresented stimuli to remove&#xD;
      statistical noise. Both the participant and the experimenter will be blind to which sounds&#xD;
      will be presented, and the selection will be automatically made by the computer. This&#xD;
      technique has been extensively used and has no known risks.&#xD;
&#xD;
      There are two main reasons that using a within-subject design reduces the required sample&#xD;
      size. First, the lack of a between-subject independent variable intuitively requires less&#xD;
      participants. Second, the level of statistical noise due to individual differences is reduced&#xD;
      (i.e., because each participant is compared with their own scores). Previous TMR studies,&#xD;
      which have found significant cuing effects, commonly used 20-25 participants. I plan to&#xD;
      include at least 30 participants in this study, after omitting participants who could not&#xD;
      complete the task and those who were not sufficiently cued during sleep. Having 30&#xD;
      participants will allow the use of more powerful statistical methods (in accordance with the&#xD;
      common rule of thumb derived from the central limit theorem, which states that means based on&#xD;
      sample sizes of more than 30 participants can be assumed to follow a normal distribution). I&#xD;
      expect the context-related TMR effect (see summary) to be smaller in magnitude relative to&#xD;
      the common effect size observed in spatial learning TMR studies (Hedge's g = 0.39 based on a&#xD;
      recent meta-analysis15). This is why I included a higher sample size. It is important to note&#xD;
      that even if this benefit will be of a smaller magnitude, as I expect, it will still be&#xD;
      indicative of the underlying neurocognitive process and therefore extremely valuable for our&#xD;
      mechanistic understanding of the role of context in sleep. Aiming at a sample size of at&#xD;
      least 30 participants and assuming an omission rate of 80%, I therefore plan to have 38&#xD;
      participants altogether.&#xD;
&#xD;
      Here is a brief summary of the procedure:&#xD;
&#xD;
      Stimuli: 12 images of spatial scenes (e.g., a beach) will each be arbitrarily associated with&#xD;
      five smaller images of objects or animals. As described later, half of the scenes will be&#xD;
      associated with a right hand motion and half with the left - and half of each of these groups&#xD;
      will be cued during sleep. Each of the 60 images will each have a unique 2D position on a&#xD;
      circular grid presented on the screen and will be accompanied by a specific, congruent sound&#xD;
      (e.g., cat - meow).&#xD;
&#xD;
      fMRI Localizer: After the participant is first put in the scanner and a basic anatomical scan&#xD;
      is complete, they will be exposed to all the different scenes while being scanned. This will&#xD;
      later be used to classify scene-specific blood-oxygen-level-dependent (BOLD) responses.&#xD;
&#xD;
      Training: First, participants will learn to associate scenes with a hand motion. They will&#xD;
      repeatedly see each scene on either the left or right side of the screen and be asked to&#xD;
      imagine touching the image on the projected screen. In this and every following training&#xD;
      block, the scenes will be presented in a participant-specific, non-randomized order. Next,&#xD;
      participant will be exposed to all 60 images' locations on the grid and asked to associate&#xD;
      the image with the scene and remember the location. The images for each scene will&#xD;
      consistently be presented in the same order within the scene, and therefore the order of the&#xD;
      60 images will be maintained throughout training. The left/right sides of the screen will be&#xD;
      used for each scene in accordance with its designated hand in the previous training stage.&#xD;
      After two rounds of exposure, participants will go through a similar positioning phase of&#xD;
      training. They will be shown the image and the scene and asked to associate them. Then, they&#xD;
      will see the circular grid without the image on it and asked to imagine touching the correct&#xD;
      location with the appropriate hand. The next screen will show the image in its correct&#xD;
      location and ask participants to signal whether or not they knew the location. The next image&#xD;
      will be presented after a short inter-trial interval. An image's location is considered&#xD;
      learned when it was marked as correct twice in a row. Blocks will be repeated in the same&#xD;
      order until all locations are learned. For the images which were already learned, the&#xD;
      repeated block will employ an alternative task to avoid over-learning while maintaining the&#xD;
      temporal order of items.&#xD;
&#xD;
      Pre-sleep test (in scanner): After training, participants will be presented with all images&#xD;
      in a pseudo-random order and asked to imagine touching their correct location on the grid&#xD;
      with the appropriate hand.&#xD;
&#xD;
      Pre-sleep test (EEG): Outside the scanner, the participant will be fitted with an EEG cap and&#xD;
      then asked to take another test. Here, images will again be randomized and participants will&#xD;
      first be asked to imagine touching the correct location and then ordered to actually touch&#xD;
      the correct position. Subsequent measures of change in spatial memory will be based on the&#xD;
      performance in this test. Throughout the task, the act of imagining the hand motion is not&#xD;
      used to decode the exact position on the screen in which the participant thinks the item&#xD;
      should be located. Instead, imagined hand motion will serve as a rough measure of hemisphere&#xD;
      specific reactivation, that will then be used to classify reactivation during sleep in the&#xD;
      EEG, as done in 64. Although this decoding will primarily be done using EEG and not fMRI, the&#xD;
      instructions to imagine hand motion are the same for all phases of the experiment in order to&#xD;
      maintain consistency throughout the task.&#xD;
&#xD;
      Sleep: During NREM (non-rapid eye movement) sleep, the sounds associated with specific images&#xD;
      will be presented unobtrusively. The scenes from which these images will be chosen will be&#xD;
      half of the right- and half of the left-handed ones. For each of these scenes, one image will&#xD;
      be cued, positioned in either the 2nd, 3rd or 4th place in that set's training sequence. The&#xD;
      choice of which sounds to present will be made in a manner that will balance pre-sleep&#xD;
      results and therefore enhance the contrast between sleep-related effects for cued and&#xD;
      non-cued images.&#xD;
&#xD;
      Post-sleep test (EEG): At least 10 minutes after the end of the nap, participants will start&#xD;
      this test, which will be identical to the Pre-sleep test (EEG).&#xD;
&#xD;
      Post-sleep test (in scanner): Identical to the Post-sleep test (in scanner). Scene-image&#xD;
      association test: Finally, participants will be shown each image in a randomized order and&#xD;
      asked to indicate which of four presented scenes is associated with it.&#xD;
&#xD;
      fMRI Localizer: Same as the first. Participants will finally be thanked, debriefed, paid and&#xD;
      dismissed.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Enrolling by invitation</overall_status>
  <start_date type="Actual">May 10, 2021</start_date>
  <completion_date type="Anticipated">November 30, 2022</completion_date>
  <primary_completion_date type="Anticipated">June 30, 2022</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Change in error rates between pre- and post-sleep for the different conditions</measure>
    <time_frame>Approximately 0.5-1.5 hours before sleep onset and approximately 0.5-1.5 hours after sleep offset within the same experimental session</time_frame>
    <description>The correct location of an image is compared with the position in which the participant has touched the touchscreen. Measured in pixels on a computer screen.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Results of neural classifier trained to distinguish between different scenes based on blood-oxygen-level-dependent activity</measure>
    <time_frame>Approximately 1.5 hours before sleep onset and approximately 1.5 hours after sleep offset within the same experimental session</time_frame>
    <description>For each positioning trial in the pre- and post-sleep tests in the scanner, the classifier will produce a measure of the evidence for each of the different scenes (i.e., contexts) being reinstated.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Results of neural classifier trained to distinguish between scenes associated with left/right hand motion based on EEG activity</measure>
    <time_frame>Approximately 0.5 hours before sleep onset and approximately 0.5 hours after sleep offset within the same experimental session</time_frame>
    <description>For each presentation of sounds during sleep, the classifier will produce a measure of the evidence for right/left hand associated contexts.</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Modulation of EEG spectral power following sound/odor presentation</measure>
    <time_frame>During sleep within the experimental session, assessed up to 1.5 hours</time_frame>
    <description>Power modulations within the sigma (12-16 Hz), theta (4-8 Hz) and delta (0.5-4 Hz) ranges immediately following sound onset. Measured across different EEG channels.</description>
  </secondary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">38</enrollment>
  <condition>Sleep</condition>
  <condition>Consolidation</condition>
  <arm_group>
    <arm_group_label>Experimental group</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Targeted memory reactivation (sounds)</intervention_name>
    <description>I will unobtrusively and repeatedly present learning-related sounds during sleep using speakers. This method was shown to improve memory in various tasks. The sounds will be presented several seconds apart and the volume will be so adjusted as not to disturb the participant's sleep. The sounds will be presented during non-rapid eye movement sleep (sleep stage 2 and slow wave sleep). The sounds presented will be congruently related to the images in the previous learning task. This manipulation is within-subject - all participants will get it, but different specific sounds will be presented for each individual participant.</description>
    <arm_group_label>Experimental group</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
        --&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
        Participants with a history of neurological disorders or of sleep disorders will be&#xD;
        excluded.&#xD;
&#xD;
        Participants who do not believe they would be able to fall asleep in the lab will be&#xD;
        excluded.&#xD;
&#xD;
        Participants with a history of metalworking, an injury with shrapnel or metal slivers, a&#xD;
        cardiac pacemaker implantation, a neuro-stimulator implantation, or claustrophobia will be&#xD;
        excluded. Participants who are or suspect they may be pregnant will not be excluded.&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <gender_based>Yes</gender_based>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>35 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <location>
    <facility>
      <name>Center for Translational Imaging - Northwestern University</name>
      <address>
        <city>Chicago</city>
        <state>Illinois</state>
        <zip>60611</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>October 2021</verification_date>
  <study_first_submitted>January 7, 2021</study_first_submitted>
  <study_first_submitted_qc>January 7, 2021</study_first_submitted_qc>
  <study_first_posted type="Actual">January 11, 2021</study_first_posted>
  <last_update_submitted>October 29, 2021</last_update_submitted>
  <last_update_submitted_qc>October 29, 2021</last_update_submitted_qc>
  <last_update_posted type="Actual">November 5, 2021</last_update_posted>
  <responsible_party>
    <responsible_party_type>Principal Investigator</responsible_party_type>
    <investigator_affiliation>Northwestern University</investigator_affiliation>
    <investigator_full_name>Eitan Schechtman-Drayman</investigator_full_name>
    <investigator_title>Principal Investigator</investigator_title>
  </responsible_party>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

