<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on November 19, 2021</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04876157</url>
  </required_header>
  <id_info>
    <org_study_id>202006124RINC</org_study_id>
    <nct_id>NCT04876157</nct_id>
  </id_info>
  <brief_title>Artificial Intelligence-aimed Point-of-care Ultrasound Image Interpretation System</brief_title>
  <official_title>Artificial Intelligence-aimed Point-of-care Ultrasound Image Interpretation System</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>National Taiwan University Hospital</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>National Taiwan University Hospital</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      This proposal is for an one-year project. In this project, we aim to investigate the&#xD;
      feasibility of using AI for sonographic image interpretation. The main project is responsible&#xD;
      for coordination between the two sub-projects and the main project, providing image&#xD;
      resources, and using U-Net (Convolutional Networks for Biomedical Image Segmentation) and&#xD;
      Transfer Learning to build up the models for image recognition and validating the efficacy of&#xD;
      the models. The purpose of Subproject 1 is to develop an image recognition system for dynamic&#xD;
      images: pericardial effusion. After building up the model, validating the efficacy and future&#xD;
      revision will be done. Subproject 2 comes out an image recognition system for static images:&#xD;
      hydronephrosis. After building up the model, validating the efficacy and future revision will&#xD;
      be done.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Ultrasound is a non-invasive and non-radiated diagnostic tool in the emergency and critical&#xD;
      care settings. In clinical practice, timely interpretation of sonographic images to&#xD;
      facilitate decision-making is essential. However, it depends on operators' experience. As&#xD;
      usual, it takes time for junior emergency physicians to have good diagnostic accuracy through&#xD;
      traditional sonographic education. How to shorten the learning This proposal is for an&#xD;
      one-year project. In this project, we aim to investigate the feasibility of using AI for&#xD;
      sonographic image interpretation. The main project is responsible for coordination between&#xD;
      the two sub-projects and the main project, providing image resources, and using U-Net&#xD;
      (Convolutional Networks for Biomedical Image Segmentation) and Transfer Learning to build up&#xD;
      the models for image recognition and validating the efficacy of the models. The purpose of&#xD;
      Subproject 1 is to develop an image recognition system for dynamic images: pericardial&#xD;
      effusion. After building up the model, validating the efficacy and future revision will be&#xD;
      done. Subproject 2 comes out an image recognition system for static images: hydronephrosis.&#xD;
      After building up the model, validating the efficacy and future revision will be done.&#xD;
&#xD;
      This pioneer study can provide two AI-assisted ultrasound image recognition systems in the&#xD;
      real clinical conditions. They can experience of clinical applications and contribute to&#xD;
      current medical education. Moreover, it can improve decision-making process and quality of&#xD;
      care in the emergency and critical care units. Furthermore, the set-up models can be used in&#xD;
      other target ultrasound image recognition in the future.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">August 1, 2020</start_date>
  <completion_date type="Anticipated">July 31, 2021</completion_date>
  <primary_completion_date type="Anticipated">July 31, 2021</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Diagnostic</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>sensitivity and specificity of AI interpretation</measure>
    <time_frame>6 months</time_frame>
    <description>increase the sensitivity and specificity of AI to interpret the ultrasound image</description>
  </primary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Anticipated">300</enrollment>
  <condition>Ultrasound Image Interpretation</condition>
  <arm_group>
    <arm_group_label>Artificial intelligence-aimed ultrasound image interpretation</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
  </arm_group>
  <intervention>
    <intervention_type>Diagnostic Test</intervention_type>
    <intervention_name>Artificial intelligence-aimed point-of-care ultrasound image interpretation system</intervention_name>
    <description>improve the sensitivity and specificity of the AI-aimed ultrasound interpretation system</description>
    <arm_group_label>Artificial intelligence-aimed ultrasound image interpretation</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
          -  patients receiving echocardiography or renal ultrasound&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
          -  patients not receiving echocardiography or renal ultrasound&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>20 Years</minimum_age>
    <maximum_age>N/A</maximum_age>
    <healthy_volunteers>No</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Wan-Ching Lien</last_name>
    <role>Principal Investigator</role>
    <affiliation>National Taiwan University Hospital</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Wan-Ching Lien, Ph D</last_name>
    <phone>+886-2-23123456</phone>
    <email>wanchinglien@ntu.edu.tw</email>
  </overall_contact>
  <overall_contact_backup>
    <last_name>Wan-Ching Lien</last_name>
    <phone>0988088719</phone>
    <email>dtemer17@yahoo.com.tw</email>
  </overall_contact_backup>
  <location>
    <facility>
      <name>Wan-Ching Lien</name>
      <address>
        <city>Taipei</city>
        <state>None Selected</state>
        <zip>100</zip>
        <country>Taiwan</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Wan-Ching Lien</last_name>
      <phone>+886223123456</phone>
      <email>wanchinglien@ntu.edu.tw</email>
    </contact>
  </location>
  <location_countries>
    <country>Taiwan</country>
  </location_countries>
  <verification_date>May 2021</verification_date>
  <study_first_submitted>May 2, 2021</study_first_submitted>
  <study_first_submitted_qc>May 2, 2021</study_first_submitted_qc>
  <study_first_posted type="Actual">May 6, 2021</study_first_posted>
  <last_update_submitted>May 6, 2021</last_update_submitted>
  <last_update_submitted_qc>May 6, 2021</last_update_submitted_qc>
  <last_update_posted type="Actual">May 7, 2021</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

