<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on November 19, 2021</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT03328455</url>
  </required_header>
  <id_info>
    <org_study_id>1086690</org_study_id>
    <nct_id>NCT03328455</nct_id>
  </id_info>
  <brief_title>Multisensory Perceptual Training in the Elderly</brief_title>
  <official_title>Multisensory Perceptual Training in the Elderly</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University of Nevada, Reno</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
  </sponsors>
  <source>University of Nevada, Reno</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      Aging impacts our unisensory perceptual abilities as well as our ability to correctly combine&#xD;
      signals from multiple sensory modalities to obtain a coherent percept of external events.&#xD;
      Elderly individuals show greater difficulty determining the temporal order of audiovisual&#xD;
      events, and possess a broadened temporal binding window (TBW) during which stimuli from&#xD;
      different modalities are likely to be integrated into a single perceptual entity. Recent&#xD;
      studies demonstrate that the TBW can be reduced following multisensory perceptual learning,&#xD;
      however, the mechanisms at work remain poorly understood. Using an adaptive training&#xD;
      paradigm, the goal of this proposed project is to examine how multisensory temporal&#xD;
      processing can be enhanced in the elderly. Specifically, the investigators will measure the&#xD;
      effect of multisensory perceptual learning on audiovisual temporal functions and its transfer&#xD;
      to unisensory temporal tasks. Combining behavioral and EEG measures, the investigators will&#xD;
      assess whether multisensory perceptual learning in the elderly changes only within the&#xD;
      unisensory processes or reflects additional cross-modal processes. Furthermore, the&#xD;
      investigators will characterize socioeconomic and health-related factors that contribute to&#xD;
      age-related deficiencies in multisensory temporal processing and identify potential training&#xD;
      outcomes for elderly subpopulations that are at greater risk. This work will provide insights&#xD;
      into the brain mechanisms underlying multisensory perception and learning in the elderly.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      The investigators will examine the training effects in the elderly by comparing the&#xD;
      behavioral and EEG measures before and after training. The investigators will include 20&#xD;
      young participants and use their baseline as target performance for training in the elderly.&#xD;
      40 elderly participants will be randomly assigned to one of the two training groups and will&#xD;
      be asked to undergo 5 days of active or passive training (see Table 1). Upon each day of&#xD;
      training, the temporal order judgment (TOJ) task will be given pre- and post-training.&#xD;
      Additionally, prior to the first day of training and at the end of the 5-day training,&#xD;
      participants will perform the audiovisual temporal recalibration testing, auditory and visual&#xD;
      TOJ tasks, as well as the EEG recording. Follow-up behavioral and EEG assessments will be&#xD;
      carried out 7 days after training to examine the persistence of training effects. Changes in&#xD;
      the multisensory temporal binding window induced by active training are shown to be stable&#xD;
      for at least one week in young adults.&#xD;
&#xD;
      Stimulus presentation. Visual and auditory stimuli will be generated using MATLAB and the&#xD;
      psychophysics toolbox. In behavioral and EEG experiments, visual and auditory stimuli will be&#xD;
      delivered via Display++ system and an AudioFile stimulus processor, respectively (Cambridge&#xD;
      Research Systems). The use of these two devices allows for precise control of stimulus&#xD;
      timing.&#xD;
&#xD;
      Active training. The investigators will use adaptive training tailored to each individual's&#xD;
      thresholds. Specifically, a two-alternative forced-choice TOJ task will be used, where&#xD;
      participants will be presented with an auditory beep (1000 Hz pure tone presented at 75 dB)&#xD;
      and a visual flash (a white circle presented on grey background) with varying stimulus onset&#xD;
      asynchronies (SOAs) and will be asked to judge the temporal order of the stimulus pair. On&#xD;
      each training day, the investigators will establish the range of SOAs for individuals based&#xD;
      on their thresholds determined from the pre-training TOJ assessment given on the same day.&#xD;
      The maximum SOA will be 0.2 log units greater than their estimated threshold and will be used&#xD;
      for both visual leading (positive SOA) and auditory leading (negative SOA) stimuli.&#xD;
      Participants will be exposed to a total of 160 trials in the training phase (8 SOAs x 20&#xD;
      repetitions). Feedback will be provided after each response.&#xD;
&#xD;
      Passive training. To control for pure practice or exposure effects, a second group of elderly&#xD;
      participants will undergo passive training. Participants will be exposed to an auditory beep&#xD;
      (1000 Hz) and a visual flash (a white circle) with varying SOAs, similarly as in the active&#xD;
      training group. The maximum SOA for each individual will be likewise determined by his or her&#xD;
      threshold from the TOJ assessment. However the participants will not be asked to perform the&#xD;
      TOJ task and no feedback will be provided. Instead, participants will perform an oddball task&#xD;
      in which they are asked to detect a dark grey circle or a high pitch beep (1500 Hz) that&#xD;
      occurs less frequently than the standard stimuli (i.e., a white circle or a 1000 Hz beep).&#xD;
      Having an oddball task in both auditory and visual modalities will ensure that participant's&#xD;
      attention is divided between the two modalities as required in the active training task 16.&#xD;
      There will be a total of 160 trials in the training phase (8 SOAs x 20 repetitions).&#xD;
&#xD;
      Behavioral assessment before and after training. The investigators will carry out a series of&#xD;
      behavioral studies to measure training effects on multisensory and unisensory temporal&#xD;
      functions using tasks such as the precision in TOJ and the temporal recalibration.&#xD;
&#xD;
      EEG assessment before and after training. The investigators will carry out a series of EEG&#xD;
      studies to measure training effects on electrophysiological measures such as ERP amplitude&#xD;
      during audiovisual temporal tasks.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Terminated</overall_status>
  <why_stopped>
    Lack of funding. Changed design.&#xD;
  </why_stopped>
  <start_date type="Actual">November 1, 2017</start_date>
  <completion_date type="Actual">October 31, 2019</completion_date>
  <primary_completion_date type="Actual">October 31, 2018</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>Randomized</allocation>
    <intervention_model>Parallel Assignment</intervention_model>
    <intervention_model_description>40 elderly participants will be randomly assigned to one of the two training groups and will be asked to undergo 5 days of active or passive training.</intervention_model_description>
    <primary_purpose>Basic Science</primary_purpose>
    <masking>Single (Participant)</masking>
    <masking_description>40 elderly participants will be randomly assigned to one of the two training groups but will not be told whether they are in the active or passive training group.</masking_description>
  </study_design_info>
  <primary_outcome>
    <measure>Threshold change</measure>
    <time_frame>At the end of 5-day training</time_frame>
    <description>Change from baseline threshold at the end of the training</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Threshold change maintenance</measure>
    <time_frame>7 days after training</time_frame>
    <description>Change from baseline threshold 7 days after training</description>
  </primary_outcome>
  <primary_outcome>
    <measure>ERP amplitude change</measure>
    <time_frame>At the end of 5-day training</time_frame>
    <description>Change from baseline ERP amplitude at the end of the training</description>
  </primary_outcome>
  <primary_outcome>
    <measure>ERP amplitude change maintenance</measure>
    <time_frame>7 days after training</time_frame>
    <description>Change from baseline ERP amplitude 7 days after training</description>
  </primary_outcome>
  <number_of_arms>2</number_of_arms>
  <enrollment type="Actual">6</enrollment>
  <condition>Healthy Aging</condition>
  <arm_group>
    <arm_group_label>Active training</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Adaptive training tailored to each individual's thresholds will be used. Specifically, a two-alternative forced-choice TOJ task will be used, where participants will be asked to judge the temporal order of the stimulus pair (an auditory beep and a visual flash) with varying SOAs. On each training day, the range of SOAs will be established for individuals based on their thresholds determined from the pre-training TOJ assessment given on the same day. The maximum SOA will be 0.2 log units greater than their estimated threshold and will be used for both visual leading (positive SOA) and auditory leading (negative SOA) stimuli. Feedback will be provided after each response.</description>
  </arm_group>
  <arm_group>
    <arm_group_label>Passive training</arm_group_label>
    <arm_group_type>Sham Comparator</arm_group_type>
    <description>To control for pure practice or exposure effects, a second group of elderly participants will undergo passive training. Participants will be exposed to the stimulus pair with varying SOAs, similarly as in the active training group. The maximum SOA for each individual will be likewise determined by his or her threshold from the TOJ assessment. However participants will not be asked to perform the TOJ task and no feedback will be provided. Instead, participants will perform an oddball task in which they are asked to detect a stimulus that occurs less frequently than the standard one. Having an oddball task in both auditory and visual modalities will ensure that participant's attention is divided between the two modalities as required in the active training task.</description>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Active training</intervention_name>
    <description>Perceptual training is task-related.</description>
    <arm_group_label>Active training</arm_group_label>
  </intervention>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Passive training</intervention_name>
    <description>Training is not task-related.</description>
    <arm_group_label>Passive training</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
          -  Age between 65 and 75 (elderly group) and between 20 and 40 (young group)&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
          -  History of epilepsy, stroke, Parkinson's disease, Alzheimer's disease, attention&#xD;
             deficit-hyperactivity disorder&#xD;
&#xD;
          -  History of head injury with loss of consciousness, brain surgery, or psychiatric&#xD;
             disorders&#xD;
&#xD;
          -  Early dementia or cognitive impairment&#xD;
&#xD;
          -  Serious vision problems (including best-corrected binocular visual acuity worse than&#xD;
             20/25)&#xD;
&#xD;
          -  Uncorrected hearing problems (pure tone threshold &gt; 40 dB for 1000-2000 Hz)&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>20 Years</minimum_age>
    <maximum_age>75 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Fang Jiang, Ph.D</last_name>
    <role>Principal Investigator</role>
    <affiliation>University of Nevada, Reno</affiliation>
  </overall_official>
  <location>
    <facility>
      <name>University of Nevada, Reno</name>
      <address>
        <city>Reno</city>
        <state>Nevada</state>
        <zip>89557</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <verification_date>November 2020</verification_date>
  <study_first_submitted>October 18, 2017</study_first_submitted>
  <study_first_submitted_qc>October 27, 2017</study_first_submitted_qc>
  <study_first_posted type="Actual">November 1, 2017</study_first_posted>
  <last_update_submitted>November 2, 2020</last_update_submitted>
  <last_update_submitted_qc>November 2, 2020</last_update_submitted_qc>
  <last_update_posted type="Actual">November 4, 2020</last_update_posted>
  <responsible_party>
    <responsible_party_type>Principal Investigator</responsible_party_type>
    <investigator_affiliation>University of Nevada, Reno</investigator_affiliation>
    <investigator_full_name>Fang Jiang</investigator_full_name>
    <investigator_title>Assitant professor</investigator_title>
  </responsible_party>
  <patient_data>
    <sharing_ipd>Yes</sharing_ipd>
    <ipd_description>Results from proposed experiments will be reported either as group findings that do not identify individual participants, or by labeling the data of each participant with a unique code that does not include the participant's name or initials. De-identified individual participant data will be shared upon request and for research purpose only starting 1 year after publication.</ipd_description>
    <ipd_info_type>Study Protocol</ipd_info_type>
    <ipd_info_type>Statistical Analysis Plan (SAP)</ipd_info_type>
    <ipd_info_type>Analytic Code</ipd_info_type>
    <ipd_time_frame>Starting 1 year after publication</ipd_time_frame>
    <ipd_access_criteria>Data will be shared upon request and for research purpose only.</ipd_access_criteria>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

