<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on November 19, 2021</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04590716</url>
  </required_header>
  <id_info>
    <org_study_id>DOC-005-2020</org_study_id>
    <nct_id>NCT04590716</nct_id>
  </id_info>
  <brief_title>Help Build an A.I. Model to Predict Myasthenia Gravis Symptom Patterns and Flares</brief_title>
  <official_title>A Digital Health Trial That Assesses Participant-driven Data Collection Using Smartphone Modules to Characterize Myasthenia Gravis Symptoms and Develop an A.I. Model to Predict Flares</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>doc.ai inc</agency>
      <agency_class>Industry</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>UCB Biopharma SRL</agency>
      <agency_class>Industry</agency_class>
    </collaborator>
  </sponsors>
  <source>doc.ai inc</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      There are limited objective measurements of MG symptoms as well as a dearth of data at a&#xD;
      granular level of MG (myasthenia gravis) symptoms and triggers occurring longitudinally.&#xD;
&#xD;
      This study is designed to use the strengths of mobile smartphones which enable&#xD;
      participant-driven real time capture of data manually and through augmented sensors such as&#xD;
      video and audio, in order to better characterize MG symptoms and flares.&#xD;
&#xD;
      The study aims to enroll approximately 200 participants for approximately 9 months until&#xD;
      analyzable data is available from at least 100 participants. Participants will complete&#xD;
      in-app surveys for 3 months with, audiovisual recording of symptoms. This will take&#xD;
      approximately 35 minutes per week after the initial survey.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Using their smartphones, potential participants will download the doc.ai research mobile app.&#xD;
      There will be a web pre-screening link where potential participants will self-screen to see&#xD;
      if they meet the basic eligibility criteria for this study. The recruitment tool for this&#xD;
      trial is developed for diversity, fairness, and inclusion. With the aim to ensure diversity&#xD;
      in the demographics of the trial to better understand the health needs of different&#xD;
      populations. So, while some interested potential participants do qualify, they may not be&#xD;
      invited into the trial due to these diversity requirements.&#xD;
&#xD;
      Patients with myasthenia gravis (MG) who meet the inclusion criteria will be invited to join&#xD;
      this digital health trial. Participants will sign the e-consent and self-enroll into the&#xD;
      study. Once their eligibility is confirmed by the study team (to ensure eligibility criteria&#xD;
      and validity of participant i.e. eliminate robo sign-ins) they will be asked to take a&#xD;
      selfie, provide documented proof of MG diagnosis, respond to a series of survey questions&#xD;
      regarding their demographics, current health, medical history, and other MG related&#xD;
      information.&#xD;
&#xD;
      Enrolled participants will have a daily brief check-in, 2 weekly check-ins and a weekly&#xD;
      check-in which will include an audiovisual check-in, and will maintain an audiovisual diary&#xD;
      to keep track of their symptoms, connect data, record their voice (to detect vocal symptoms:&#xD;
      weakness, nasality) and take videos of their face (to detect facial symptoms: ocular, mouth&#xD;
      droop) on a daily to weekly basis through the various data collecting modules in the doc.ai&#xD;
      research app for the duration of their study participation. doc.ai's digital health trial&#xD;
      platform will be leveraged to collect this data.&#xD;
&#xD;
      The study aims to enroll approximately 200 participants in approximately 9 months. It is&#xD;
      expected that a minimum of 100 participants will be included in the final analysis as at any&#xD;
      given time there will be a lag between potential participants expressing interest in the&#xD;
      study, their eligibility being assessed by the PI, and participants completing all required&#xD;
      study procedures.&#xD;
&#xD;
      At the end of their participation, participants will be asked to complete a questionnaire.&#xD;
      After the participant has completed their final survey, they will be able to connect to a&#xD;
      link redeemable as an Amazon.com gift card worth $250. All participants will also receive an&#xD;
      end-of-trial-summary of the data that they had collected during the study. No medical advice&#xD;
      or direction will be given based on this study.&#xD;
&#xD;
      In addition, in the final survey participants will be asked if they would be willing to&#xD;
      complete a usability interview after their participation in this trial has ended. This subset&#xD;
      of participants invited to be part of a follow-up usability interview will include those who&#xD;
      complete all study required procedures and some who may not have completed all study required&#xD;
      procedures, in order to assess usability experience of the app for the duration of their&#xD;
      participation. Participants will be contacted at their end of their period of participation&#xD;
      until a total of 10-15 participants successfully complete the usability interview.&#xD;
      Participants who successfully complete the usability interview will receive a link for a $50&#xD;
      in Amazon.com gift card via the app.&#xD;
&#xD;
      For this study the data and, audio and video recordings will be captured directly on the&#xD;
      doc.ai research app and securely stored on a HIPAA compliant cloud provider (Google Cloud&#xD;
      Platform).&#xD;
&#xD;
      This data will be used to understand the patterns of symptoms and triggers in order to better&#xD;
      characterize factors such as the length and timing of flares and any unique symptom patterns&#xD;
      in order to create more objective measures of MG symptoms. Ultimately this data would be used&#xD;
      to build a machine learning model that could predict MG symptom flares.&#xD;
&#xD;
      Primary Objective:&#xD;
&#xD;
      Use a collection of digital health modules on the smartphone to collect myasthenia gravis&#xD;
      (MG) symptoms and triggers to better characterize symptom patterns and flares.&#xD;
&#xD;
      Secondary Objective:&#xD;
&#xD;
      Use the data collected to develop an A.I. model to detect and/or predict symptom flares.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Completed</overall_status>
  <start_date type="Actual">October 2, 2020</start_date>
  <completion_date type="Actual">July 26, 2021</completion_date>
  <primary_completion_date type="Actual">July 26, 2021</primary_completion_date>
  <study_type>Observational</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <observational_model>Cohort</observational_model>
    <time_perspective>Prospective</time_perspective>
  </study_design_info>
  <primary_outcome>
    <measure>Audiovisual recording of voice exercises to detect patterns and changes in voice and facial symptoms</measure>
    <time_frame>After enrollment, 3 months with in-app twice a week audiovisual recording of symptoms.</time_frame>
    <description>participants to complete the audio and visual data modules designed to capture patient MG symptoms (especially ocular and voice).&#xD;
e.g&#xD;
Vocal e.g.:&#xD;
Say &quot;papapapa&quot; for 4 seconds&#xD;
Say &quot;tatatatata&quot; for 4 seconds&#xD;
Say &quot;kakakaka&quot; 4 seconds&#xD;
Say &quot;mamamama&quot; 4 seconds&#xD;
Say &quot;papapapa&quot; 4 seconds&#xD;
Say &quot;buttercup, buttercup, buttercup&quot; 4 seconds&#xD;
Say &quot;aaaahhh&quot; and hold it as long as you can&#xD;
Counting e.g.:&#xD;
Look straight at the camera for 4 seconds&#xD;
Count as precisely as possible from 1 to 25 while looking up&#xD;
Look straight at the camera for 4 seconds&#xD;
The recordings will be used to detect change from baseline and any patterns that may occur. This will be used to analyze where and if different features are linked to see if a single or combined effect of the features is connected to flare frequency and/or severity.</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Completion of MG-Quality of Life assessment</measure>
    <time_frame>Approximately 10 minutes each week for 3 months.</time_frame>
    <description>Participants complete MG activities of Daily living and MG-Quality of Life assessments weekly. This assessment has been adapted from www.myasthenia.org/healthprofessionals/educationalmaterials.aspx</description>
  </secondary_outcome>
  <enrollment type="Actual">113</enrollment>
  <condition>Myasthenia Gravis</condition>
  <intervention>
    <intervention_type>Other</intervention_type>
    <intervention_name>Data Collection</intervention_name>
    <description>This is a non-interventional study conducted on the participant's smartphones to record MG related symptoms and conditions.</description>
  </intervention>
  <eligibility>
    <study_pop>
      <textblock>
        Patients with myasthenia gravis (MG) who meet the inclusion criteria will be invited to&#xD;
        join this digital health trial.&#xD;
&#xD;
        There will be a web pre-screening link where potential participants will self-screen to see&#xD;
        if they meet the basic eligibility criteria for this study. The recruitment tool for this&#xD;
        trial is developed for diversity, fairness, and inclusion. With the aim to ensure diversity&#xD;
        in the demographics of the trial to better understand the health needs of different&#xD;
        populations. So, while some interested potential participants do qualify, they may not be&#xD;
        invited into the trial due to these diversity requirements.&#xD;
      </textblock>
    </study_pop>
    <sampling_method>Non-Probability Sample</sampling_method>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
          1. Must have a documented diagnosis of Myasthenia Gravis&#xD;
&#xD;
          2. Must have ocular (eye drooping) and/or bulbar (speech) symptoms&#xD;
&#xD;
          3. Must be over the age of 18&#xD;
&#xD;
          4. Must reside in the US for the duration of the study&#xD;
&#xD;
          5. Must be able to read, understand, and write in English&#xD;
&#xD;
          6. Must have a smartphone supported by the doc.ai research app (iOS and Android)&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
        None&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>N/A</maximum_age>
    <healthy_volunteers>No</healthy_volunteers>
  </eligibility>
  <location>
    <facility>
      <name>Doc.Ai Mobile Based</name>
      <address>
        <city>Palo Alto</city>
        <state>California</state>
        <zip>94301</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <link>
    <url>https://ghr.nlm.nih.gov/condition/myasthenia-gravis</url>
    <description>&quot;Myasthenia gravis - Genetics Home Reference - NIH.&quot;</description>
  </link>
  <results_reference>
    <citation>Kent RD, Kent JF, Rosenbek JC. Maximum performance tests of speech production. J Speech Hear Disord. 1987 Nov;52(4):367-87. Review.</citation>
    <PMID>3312817</PMID>
  </results_reference>
  <results_reference>
    <citation>Konopka BM, Lwow F, Owczarz M, Łaczmański Ł. Exploratory data analysis of a clinical study group: Development of a procedure for exploring multidimensional data. PLoS One. 2018 Aug 23;13(8):e0201950. doi: 10.1371/journal.pone.0201950. eCollection 2018.</citation>
    <PMID>30138442</PMID>
  </results_reference>
  <results_reference>
    <citation>Zhou ZR, Wang WW, Li Y, Jin KR, Wang XY, Wang ZW, Chen YS, Wang SJ, Hu J, Zhang HN, Huang P, Zhao GZ, Chen XX, Li B, Zhang TS. In-depth mining of clinical data: the construction of clinical prediction model with R. Ann Transl Med. 2019 Dec;7(23):796. doi: 10.21037/atm.2019.08.63.</citation>
    <PMID>32042812</PMID>
  </results_reference>
  <results_reference>
    <citation>Kang H. The prevention and handling of the missing data. Korean J Anesthesiol. 2013 May;64(5):402-6. doi: 10.4097/kjae.2013.64.5.402. Epub 2013 May 24.</citation>
    <PMID>23741561</PMID>
  </results_reference>
  <results_reference>
    <citation>Borza D, Darabant AS, Danescu R. Real-Time Detection and Measurement of Eye Features from Color Images. Sensors (Basel). 2016 Jul 16;16(7). pii: E1105. doi: 10.3390/s16071105.</citation>
    <PMID>27438838</PMID>
  </results_reference>
  <results_reference>
    <citation>Hegde S, Shetty S, Rai S, Dodderi T. A Survey on Machine Learning Approaches for Automatic Detection of Voice Disorders. J Voice. 2019 Nov;33(6):947.e11-947.e33. doi: 10.1016/j.jvoice.2018.07.014. Epub 2018 Oct 11. Review.</citation>
    <PMID>30316551</PMID>
  </results_reference>
  <results_reference>
    <citation>Duffy, JR: Motor Speech Disorders. Substrates, Differential Diagnosis and Management (1st ed). St. Louis, 1995, Mosby.</citation>
  </results_reference>
  <results_reference>
    <citation>Duffy, JR: Motor Speech Disorders. Substrates, Differential Diagnosis and Management (2nd ed). New York, 2005, Elsevier Health Sciences.</citation>
  </results_reference>
  <results_reference>
    <citation>T. Baltrusaitis, A. Zadeh, Y. C. Lim and L. Morency,</citation>
  </results_reference>
  <results_reference>
    <citation>Panayotov V., Chen G., Povey D., Khudanpur S. (2015). Librispeech: an ASR corpus based on public domain audio books, in Proceedings of the ICASSP (South Brisbane, QLD:), 5206-5210</citation>
  </results_reference>
  <verification_date>July 2021</verification_date>
  <study_first_submitted>October 2, 2020</study_first_submitted>
  <study_first_submitted_qc>October 9, 2020</study_first_submitted_qc>
  <study_first_posted type="Actual">October 19, 2020</study_first_posted>
  <last_update_submitted>July 27, 2021</last_update_submitted>
  <last_update_submitted_qc>July 27, 2021</last_update_submitted_qc>
  <last_update_posted type="Actual">July 29, 2021</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Myasthenia Gravis</mesh_term>
    <mesh_term>Muscle Weakness</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>Yes</sharing_ipd>
    <ipd_description>Data will be reviewed, and analysis will be done by personnel of doc.ai, and the medical experts. Population-level results of the data analysis in the form of a presentation/report, as well as the resulting proof-of-concept predictive AI model, will be shared with UCB Biopharma (SRL) (who are funding this study). No participant PII or PHI will be shared with UCB Biopharma (SRL) or any other 3rd parties.</ipd_description>
    <ipd_info_type>Study Protocol</ipd_info_type>
    <ipd_info_type>Informed Consent Form (ICF)</ipd_info_type>
    <ipd_info_type>Clinical Study Report (CSR)</ipd_info_type>
    <ipd_time_frame>At the end of the study, upon completion of the analysis.</ipd_time_frame>
  </patient_data>
  <provided_document_section>
    <provided_document>
      <document_type>Informed Consent Form</document_type>
      <document_has_protocol>No</document_has_protocol>
      <document_has_icf>Yes</document_has_icf>
      <document_has_sap>No</document_has_sap>
      <document_date>October 8, 2020</document_date>
      <document_url>https://ClinicalTrials.gov/ProvidedDocs/16/NCT04590716/ICF_000.pdf</document_url>
    </provided_document>
  </provided_document_section>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

