<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on November 19, 2021</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04997577</url>
  </required_header>
  <id_info>
    <org_study_id>P01AG055365</org_study_id>
    <secondary_id>5P01AG055365-04</secondary_id>
    <nct_id>NCT04997577</nct_id>
  </id_info>
  <brief_title>Speech Perception and High Cognitive Demand</brief_title>
  <official_title>Auditory-cognitive Training Paradigm (NIH P01 Project - Speech Perception With High Cognitive Demand)</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University of Maryland, College Park</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>National Institute on Aging (NIA)</agency>
      <agency_class>NIH</agency_class>
    </collaborator>
  </sponsors>
  <source>University of Maryland, College Park</source>
  <oversight_info>
    <has_dmc>Yes</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>No</is_fda_regulated_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      With advancing age, adults experience increasing speech understanding difficulties in&#xD;
      challenging situations. Currently, speech-in-noise difficulties are rehabilitated by&#xD;
      providing hearing aids. For older normal-hearing adults, however, hearing devices do not&#xD;
      provide much benefit since these adults do not have decreased hearing sensitivity. The goal&#xD;
      of the &quot;Speech Perception and High Cognitive Demand&quot; project is to evaluate the benefit of a&#xD;
      new auditory-cognitive training paradigm. In the present study neural (as measured by&#xD;
      pupillometry and magnetoencephalography) and behavioral changes of speech-in-noise perception&#xD;
      from pretest to posttest will be examined in older adults (age 65 - 85 years) assigned to one&#xD;
      of three training groups: 1) Active Control Group: sessions of watching informational videos,&#xD;
      2) Auditory Training Group: sessions of auditory training listening to one of two speakers in&#xD;
      everyday scenarios (e.g., driving directions) and needing to recall what one speaker said in&#xD;
      the previous sentence, and 3) Auditory-cognitive training group: identical to the auditory&#xD;
      training group, except participants will be asked to remember information from two previous&#xD;
      sentences. Changes in speech-in-noise perception will be examined for the three groups of&#xD;
      older adults and gains will be compared to a control group of young, normal hearing adults&#xD;
      (18-30 years) that is not part of the clinical trial and will not undergo any training.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      With advancing age, adults experience increasing difficulties in understanding speech in&#xD;
      challenging situations, such as difficulty with understanding others in a noisy restaurant.&#xD;
      Speech-in-noise difficulties are typically rehabilitated by providing hearing aids. For older&#xD;
      normal-hearing adults, however, hearing devices do not provide much benefit since these&#xD;
      adults do not have decreased hearing sensitivity. For these adults, communication&#xD;
      difficulties persist in everyday life situations and can even lead to social withdrawal,&#xD;
      isolation, and depression. A growing body of studies demonstrates that combined&#xD;
      auditory-cognitive training paradigms can offer speech-in-noise benefits to adults with&#xD;
      hearing loss that could prevent the consequences listed above.&#xD;
&#xD;
      The goal of the &quot;Speech Perception with High Cognitive Demand&quot; project is to evaluate the&#xD;
      benefit of a new auditory-cognitive training paradigm for older normal-hearing adults. The&#xD;
      investigators developed an American English version of the Nottingham (UK) PLUS training&#xD;
      paradigm in which listeners are asked to focus and listen to one speaker while ignoring&#xD;
      another speaker. Although it cannot ensure that every participant will experience direct&#xD;
      significant benefit from the training, the paradigm is being designed to optimally enhance&#xD;
      the possibility of benefit: an adaptive procedure is employed to train each individual at&#xD;
      their own level and to make the task challenging. In a separate training condition, a&#xD;
      short-term memory component is added to the original training paradigm to also enhance the&#xD;
      cognitive skills of the participants. In addition, the training is implemented on&#xD;
      touch-screen laptops, making at-home training possible. This way, training is provided in a&#xD;
      realistic setting which will ensure a better transfer of the trained skills to daily&#xD;
      communication situations. The trial consists of three conditions: 1) Auditory only training,&#xD;
      2) Auditory-cognitive training, and 3) Active control of informational videos.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Recruiting</overall_status>
  <start_date type="Actual">September 27, 2021</start_date>
  <completion_date type="Anticipated">May 30, 2022</completion_date>
  <primary_completion_date type="Anticipated">May 15, 2022</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>Randomized</allocation>
    <intervention_model>Parallel Assignment</intervention_model>
    <primary_purpose>Treatment</primary_purpose>
    <masking>Single (Participant)</masking>
    <masking_description>Participants will be unaware of the number and types of treatment groups.</masking_description>
  </study_design_info>
  <primary_outcome>
    <measure>Change in speech-in-noise perception</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>In the Quick Speech-in-noise task (QSIN). Participants listen to a target female speaker in babble across six sentences (i.e., one list) presented at different signal-to-noise ratios (SNRs). Each sentence has five target words that participants are asked to repeat at the end of each sentence. Within each list, the first sentence is played with a 25 dB SNR and SNR decreases as the list progresses in increments of 5 dB., with the final sentence played at 0 dB. The average SNR score is calculated across several lists. The average SNR score is calculated across several lists. Scores range from -4.5 to 25.5 dB. Higher scores indicate greater SNR loss (i.e., worse hearing).</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Audiobook - Change in pupillary response</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>During an audiobook listening task, pupil dilations are recorded as an objective measure of listening effort, with larger pupil dilations indicating increased listening effort. Change in pupil dilations at pre and posttest (before and after training, respectively) will be measured. In the audiobook listening task, audiobook segments will be presented to participants at signal-to-noise ratios (SNRs) of quiet, 0 dB, -6 dB, and in babble (with four background speakers). Participants listen to each audiobook segment three times.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Audiobook - Change in magnetoencephalography (MEG) temporal response function</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>During an audiobook listening task, MEG neural activity will be recorded. The investigators will evaluate change in the temporal response function (TRF). The TRF relates how the brain responds to acoustic stimuli and can be viewed as evoked responses to the continuous speech. Audiobook segments will be presented to participants at signal-to-noise ratios (SNRs) of quiet, 0 dB, -6 dB, and in babble (with four background speakers). Participants listen to each audiobook segment three times.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Change in Magnetoencephalography (MEG) stimulus reconstruction accuracies and integration window analysis</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>During an audiobook listening task, MEG neural activity will be recorded. The investigators will measure how far the neural response tracks the speech stimulus by stimulus reconstruction accuracies and how the stimulus reconstruction accuracy builds up over time by integration window analysis. Audiobook segments will be presented to participants at signal-to-noise ratios (SNRs) of quiet, 0 dB, -6 dB, and in babble (with four background speakers). Participants listen to each audiobook segment three times.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Audiobook - Change in frequency following response (FFR)</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>During an audiobook listening task, MEG neural activity will be recorded. The investigators will measure change in the FFR. The FFR is a measure of neural activity in response to a sound and serves as a measure of neural sound encoding. Larger FFR amplitudes indicate greater representations of an auditory stimulus. Audiobook segments will be presented to participants at signal-to-noise ratios (SNRs) of quiet, 0 dB, -6 dB, and in babble (with four background speakers). Participants listen to each audiobook segment three times and after each repetition.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Audiobook - Change in Magnetoencephalography (MEG) network localized granger causality</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>During an audiobook listening task MEG neural activity will be recorded. The investigators will measure the network localized granger causality (NLGC) to measure the networked activity of the cortex. Audiobook segments will be presented to participants at signal-to-noise ratios (SNRs) of quiet, 0 dB, -6 dB, and in babble (with four background speakers). Participants listen to each audiobook segment three times and after each repetition.</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Audiobook - Change in subjective ratings</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>During an audiobook listening task, participants provide subjective listening effort and speech intelligibility ratings. This is an experimenter-generated measure. Audiobook segments will be presented to participants at signal-to-noise ratios (SNRs) of quiet, 0 dB, -6 dB, and in babble (with four background speakers). Participants listen to each audiobook segment three times and after each triad of audiobook segments, participants answer subjective intelligibility and listening effort questions. Scores are on a scale from 0 to 10 in increments of 1. Higher subjective intelligibility ratings indicate easier intelligibility whereas higher listening effort indicates more listening effort was exerted while listening to the audiobook segments.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Tone cloud - Change in auditory stream segregation accuracy</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>As a measure of change in auditory stream segregation, participants complete a stochastic figure-ground (SFG) task, in which participants listen to inharmonious 50 ms tones with random onsets for six seconds. For half of these stimuli, a figure &quot;pops-out&quot; from the background tones, in which a number of tones begin at the same time, making a chord. This figure chord repeats 12 times over the course of three seconds. Participants indicate when they detect a figure chord. The stimuli that contain the figure chord have chords consisting of 4, 6, or 8 tones. Figure detection accuracy will be calculated as percent correct for each figure chord condition.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Tone cloud - Change in auditory stream segregation reaction time (RT)</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>As a measure of change in auditory stream segregation, participants complete a stochastic figure-ground (SFG) task, in which participants listen to inharmonious 50 ms tones with random onsets for six seconds. For half of these stimuli, a figure &quot;pops-out&quot; from the background tones, in which a number of tones begin at the same time, making a chord. This figure chord repeats 12 times over the course of three seconds. Participants indicate when they detect a figure chord. The stimuli that contain the figure chord have chords consisting of 4, 6, or 8 tones. RT to the figure present stimuli will be calculated as average RT for each figure chord condition.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>N-back task - Change in accuracy</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>Because the auditory and auditory-cognitive training paradigms involve a working memory component, pre and posttests of an n-back working memory measure are included. Participants complete four blocks in which they listen to a string of letters spoken by a female speaker. Participants are asked to click a button when a letter occurred n-back. Each block increases in the nth element that needs to be remember, starting at n = 1 (Block 1) and ending at n = 4 (Block 4). Participants' accuracy as percent correct are averaged for each level of n.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>N-back task - Change in response time (RT)</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>Because the auditory and auditory-cognitive training paradigms involve a working memory component, pre and posttests of an n-back working memory measure are included. Participants complete four blocks in which they listen to a string of letters spoken by a female speaker. Participants are asked to click a button when a letter occurred n-back. Each block increases in the nth element that needs to be remember, starting at n = 1 (Block 1) and ending at n = 4 (Block 4). Participants' RTs for correct hits are measured and averaged for each level of n.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Reading Span (RSpan) - Change in working memory (WM)</measure>
    <time_frame>Week 1-2 (pretest) and Week 5-6 (posttest)</time_frame>
    <description>Pre and posttests of an RSpan working memory measure are included. Participants read sets of short sentences consisting of 3, 4, 5, or 6 words per sentence. Half of the sentences are anomalous, and the other half are not. Participants are asked to read each sentence aloud one word at a time and then indicate whether the sentence made semantic sense or not. At the end of each set, participants are asked to remember the last word of each sentence, in order, to the best of their ability. Set sizes increase as the task progresses. Everyone starts with a set size of three words per sentence and ends at a set size of six words per sentence; there are three sentences for each set size. The final score is based on the total number of words recalled. Scores range from 0 to 54, with higher scores indicating better performance.</description>
  </secondary_outcome>
  <number_of_arms>3</number_of_arms>
  <enrollment type="Anticipated">100</enrollment>
  <condition>Speech Intelligibility</condition>
  <condition>Aging</condition>
  <arm_group>
    <arm_group_label>Auditory training paradigm</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Participants perform speech-in-noise perception tasks with real-world scenarios.</description>
  </arm_group>
  <arm_group>
    <arm_group_label>Auditory-cognitive training paradigm</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Participants perform speech-in-noise perception tasks with real-world scenarios. A short-term memory component is added to the training paradigm to make the task more engaging and challenging.</description>
  </arm_group>
  <arm_group>
    <arm_group_label>Active control of informational videos</arm_group_label>
    <arm_group_type>Sham Comparator</arm_group_type>
    <description>Individuals are asked to watch informational videos.</description>
  </arm_group>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Auditory-cognitive training paradigm</intervention_name>
    <description>The investigators developed an American English version of the Nottingham (UK) PLUS training paradigm in which listeners are asked to focus and listen to one speaker while ignoring another speaker. The paradigm is designed to optimally enhance the possibility of benefit: an adaptive procedure is employed to train each individual at their own level to make the task challenging. A short-term memory component, in which listeners are asked to remember what a designated speaker said two sentences prior, was added to the auditory training paradigm to make the task more challenging. Participants will be asked to recall the keywords of the to-be-attended speaker. The sentences will be presented in a two-down one-up adaptive procedure in which the ratio of the levels of the to-be-attended and to-be-ignored speaker will be adjusted based on the correctly recalled key words.</description>
    <arm_group_label>Auditory-cognitive training paradigm</arm_group_label>
  </intervention>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Auditory training paradigm</intervention_name>
    <description>The investigators developed an American English version of the Nottingham (UK) PLUS training paradigm in which listeners are asked to focus and listen to one speaker while ignoring another speaker. The paradigm is designed to optimally enhance the possibility of benefit: an adaptive procedure is employed to train each individual at their own level to make the task challenging. Participants will be asked to recall the keywords of the to-be-attended speaker. The sentences will be presented in a two-down one-up adaptive procedure in which the ratio of the levels of the to-be-attended and to-be-ignored speaker will be adjusted based on the correctly recalled key words.</description>
    <arm_group_label>Auditory training paradigm</arm_group_label>
  </intervention>
  <intervention>
    <intervention_type>Behavioral</intervention_type>
    <intervention_name>Active Control of Informational videos</intervention_name>
    <description>Individuals are asked to watch informational videos and answer questions related to the content of the videos.</description>
    <arm_group_label>Active control of informational videos</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
          -  Age between 65-85 years&#xD;
&#xD;
          -  Normal hearing (pure tone thresholds &lt;= 25 dB HL from 250-8000 Hz)&#xD;
&#xD;
          -  Normal or corrected-to-normal vision&#xD;
&#xD;
          -  Dominant language: American English&#xD;
&#xD;
          -  Education: a high school diploma or higher educational level&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
          -  Middle-ear or inner-ear pathology&#xD;
&#xD;
          -  Non-native speaker of English&#xD;
&#xD;
          -  Inability to complete all training sessions within a pre-specified time window (e.g.,&#xD;
             due to unexpected schedule restrictions)&#xD;
&#xD;
          -  Learning disorders&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>65 Years</minimum_age>
    <maximum_age>85 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Samira B Anderson, PhD</last_name>
    <role>Principal Investigator</role>
    <affiliation>University of Maryland, College Park</affiliation>
  </overall_official>
  <overall_official>
    <last_name>Jonathan Z Simon, PhD</last_name>
    <role>Principal Investigator</role>
    <affiliation>University of Maryland, College Park</affiliation>
  </overall_official>
  <overall_official>
    <last_name>Stefanie E Kuchinsky, PhD</last_name>
    <role>Principal Investigator</role>
    <affiliation>Walter Reed National Military Medical Center</affiliation>
  </overall_official>
  <overall_contact>
    <last_name>Regina C Calloway, PhD</last_name>
    <phone>240-464-5313</phone>
    <email>rcallowa@umd.edu</email>
  </overall_contact>
  <overall_contact_backup>
    <last_name>Jonathan Z Simon, PhD</last_name>
    <phone>301-437-3546</phone>
    <email>jzsimon@umd.edu</email>
  </overall_contact_backup>
  <location>
    <facility>
      <name>Department of Hearing and Speech Sciences</name>
      <address>
        <city>College Park</city>
        <state>Maryland</state>
        <zip>20742</zip>
        <country>United States</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Samira B Anderson, PhD</last_name>
    </contact>
    <investigator>
      <last_name>Jason Dunlap</last_name>
      <role>Sub-Investigator</role>
    </investigator>
    <investigator>
      <last_name>Dushyanthi Karunathilake</last_name>
      <role>Sub-Investigator</role>
    </investigator>
    <investigator>
      <last_name>Regina Calloway, PhD</last_name>
      <role>Sub-Investigator</role>
    </investigator>
  </location>
  <location>
    <facility>
      <name>Maryland Neuroimaging Center</name>
      <address>
        <city>College Park</city>
        <state>Maryland</state>
        <zip>20742</zip>
        <country>United States</country>
      </address>
    </facility>
    <status>Recruiting</status>
    <contact>
      <last_name>Sandy Collier</last_name>
    </contact>
    <contact_backup>
      <last_name>Stefanie Kuchinsky, PhD</last_name>
    </contact_backup>
    <investigator>
      <last_name>Jason Dunlap</last_name>
      <role>Sub-Investigator</role>
    </investigator>
    <investigator>
      <last_name>Regina Calloway, PhD</last_name>
      <role>Sub-Investigator</role>
    </investigator>
    <investigator>
      <last_name>Dushyanthi Karunathilake</last_name>
      <role>Sub-Investigator</role>
    </investigator>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <reference>
    <citation>Ferguson MA, Henshaw H. Auditory training can improve working memory, attention, and communication in adverse conditions for adults with hearing loss. Front Psychol. 2015 May 28;6:556. doi: 10.3389/fpsyg.2015.00556. eCollection 2015.</citation>
    <PMID>26074826</PMID>
  </reference>
  <reference>
    <citation>Lawrence BJ, Jayakody DMP, Henshaw H, Ferguson MA, Eikelboom RH, Loftus AM, Friedland PL. Auditory and Cognitive Training for Cognition in Adults With Hearing Loss: A Systematic Review and Meta-Analysis. Trends Hear. 2018 Jan-Dec;22:2331216518792096. doi: 10.1177/2331216518792096.</citation>
    <PMID>30092719</PMID>
  </reference>
  <verification_date>September 2021</verification_date>
  <study_first_submitted>July 16, 2021</study_first_submitted>
  <study_first_submitted_qc>August 2, 2021</study_first_submitted_qc>
  <study_first_posted type="Actual">August 9, 2021</study_first_posted>
  <last_update_submitted>September 27, 2021</last_update_submitted>
  <last_update_submitted_qc>September 27, 2021</last_update_submitted_qc>
  <last_update_posted type="Actual">September 28, 2021</last_update_posted>
  <responsible_party>
    <responsible_party_type>Principal Investigator</responsible_party_type>
    <investigator_affiliation>University of Maryland, College Park</investigator_affiliation>
    <investigator_full_name>Regina Calloway</investigator_full_name>
    <investigator_title>Postdoctoral Affiliate</investigator_title>
  </responsible_party>
  <keyword>Auditory-cognitive training</keyword>
  <keyword>Aging</keyword>
  <keyword>Speech-in-noise perception</keyword>
  <patient_data>
    <sharing_ipd>Yes</sharing_ipd>
    <ipd_description>Plan to use the Digital Repository at the University of Maryland (DRUM) platform for data storage and sharing.</ipd_description>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

