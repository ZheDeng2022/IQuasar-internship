<clinical_study>
  <!-- This xml conforms to an XML Schema at:
    https://clinicaltrials.gov/ct2/html/images/info/public.xsd -->
  <required_header>
    <download_date>ClinicalTrials.gov processed this data on November 19, 2021</download_date>
    <link_text>Link to the current ClinicalTrials.gov record.</link_text>
    <url>https://clinicaltrials.gov/show/NCT04721990</url>
  </required_header>
  <id_info>
    <org_study_id>20-1857</org_study_id>
    <nct_id>NCT04721990</nct_id>
  </id_info>
  <brief_title>Subjective and Objective Performance With the SONNET2EAS</brief_title>
  <official_title>Subjective and Objective Performance With the SONNET2EAS</official_title>
  <sponsors>
    <lead_sponsor>
      <agency>University of North Carolina, Chapel Hill</agency>
      <agency_class>Other</agency_class>
    </lead_sponsor>
    <collaborator>
      <agency>Med-El Corporation</agency>
      <agency_class>Industry</agency_class>
    </collaborator>
  </sponsors>
  <source>University of North Carolina, Chapel Hill</source>
  <oversight_info>
    <has_dmc>No</has_dmc>
    <is_fda_regulated_drug>No</is_fda_regulated_drug>
    <is_fda_regulated_device>Yes</is_fda_regulated_device>
    <is_unapproved_device>Yes</is_unapproved_device>
  </oversight_info>
  <brief_summary>
    <textblock>
      Purpose: The purpose of this study is to demonstrate the non-inferiority and new features of&#xD;
      an external speech processor for cochlear implant recipients.&#xD;
&#xD;
      Participants: This study seeks to enroll 15 cochlear implant recipients listening to previous&#xD;
      technology.&#xD;
&#xD;
      Procedures (methods): Subjects will be programmed and tested with old and new technology.&#xD;
    </textblock>
  </brief_summary>
  <detailed_description>
    <textblock>
      Candidacy criteria for cochlear implantation include adults with normal-to-moderate&#xD;
      low-frequency hearing and severe-to-profound high-frequency sensorineural hearing loss. A&#xD;
      cochlear implant system includes two parts: 1) the internal electrode array that is&#xD;
      surgically implanted into the cochlea, and 2) the external audio processor that picks up the&#xD;
      acoustic signal. The external audio processor sends the converted acoustic signal to the&#xD;
      internal device, which is presented as electrical pulses via individual electrodes and&#xD;
      interpreted by the brain as sound.&#xD;
&#xD;
      When acoustic hearing in the implanted ear is preserved postoperatively, cochlear implant&#xD;
      recipients are fit with an electric-acoustic stimulation (EAS) device. An EAS device combines&#xD;
      acoustic and cochlear implant technology into a single device to provide acoustic&#xD;
      amplification of the aidable low-frequency hearing region and electric stimulation of the&#xD;
      mid-to-high frequency region. Cochlear implant recipients demonstrate a significant&#xD;
      improvement when listening with EAS as compared to listening with acoustic or electric&#xD;
      stimulation alone on measures of speech understanding and subjective benefit. The benefit is&#xD;
      thought to be due to the addition of acoustic low-frequency cues.&#xD;
&#xD;
      The MED-EL SONNETEAS system was approved for commercial use in 2017 for adults (MED-EL,&#xD;
      Innsbruck, Austria). Recently, the SONNET2EAS was approved and is currently MED-EL&#xD;
      Corporation's newest EAS audio processor. While processing with the SONNET2EAS is currently&#xD;
      the similar to that of the SONNETEAS, updated &quot;front-end features&quot;, including improved&#xD;
      artificial intelligence, are available within the device but have not been approved for&#xD;
      commercial use.&#xD;
&#xD;
      Front-end processing occurs in the external audio processor prior to the coding of the&#xD;
      signal. This processing is intended to optimize signal perception in variable environments&#xD;
      (e.g. complex, noisy listening conditions). Currently, the SONNETEAS and SONNET2EAS have two&#xD;
      microphones receiving the incoming signal, which are then manipulated to allow for wind noise&#xD;
      reduction (WNR) and directional processing. These features are included within the currently&#xD;
      approved &quot;Automatic Sound Management (ASM) 2.0&quot; and primarily seek to improve speech&#xD;
      perception in the presence of noise. ASM 3.0 may offer cochlear implant listeners an&#xD;
      improvement in speech understanding, specifically in complex or noisy listening situations,&#xD;
      and potentially improve ease of listening in a dynamic environment. Listeners of devices with&#xD;
      front-end processing demonstrate similar or improved performance than with devices without&#xD;
      this technology - dependent on the listening situation.&#xD;
&#xD;
      The aim of the present investigation is to compare objective and subjective outcomes with the&#xD;
      new front-end features to the current generation in EAS device users, using a within subject&#xD;
      design.&#xD;
    </textblock>
  </detailed_description>
  <overall_status>Withdrawn</overall_status>
  <why_stopped>
    Recruitment was never initiated, and no subject participated.&#xD;
  </why_stopped>
  <start_date type="Anticipated">April 2021</start_date>
  <completion_date type="Anticipated">April 2023</completion_date>
  <primary_completion_date type="Anticipated">April 2023</primary_completion_date>
  <phase>N/A</phase>
  <study_type>Interventional</study_type>
  <has_expanded_access>No</has_expanded_access>
  <study_design_info>
    <allocation>N/A</allocation>
    <intervention_model>Single Group Assignment</intervention_model>
    <primary_purpose>Treatment</primary_purpose>
    <masking>None (Open Label)</masking>
  </study_design_info>
  <primary_outcome>
    <measure>Difference in Consonant-Nucleus-Consonant (CNC) Words Scores</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Testing open-set word understanding. Recorded CNC Words lists will be presented to the participant. Resultant score is a percentage of words correct with a range of 0% to 100%. A higher score is better. Scores obtained with the SONNETEAS will be compared to those obtained with the SONNET2EAS, programmed with Automatic Sound Management 3.0.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Difference in Hearing-in-Noise-Test (HINT) Sentences in Diffuse Noise</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Testing open-set sentence understanding with background noise present. Recorded Hearing-in-Noise-Test (HINT) sentences in diffuse noise will be presented to participant. Resultant score is a percentage of words correct with a range of 0% to 100%. A higher score is better. Scores obtained with the SONNETEAS will be compared to those obtained with the SONNET2EAS, programmed with Automatic Sound Management 3.0.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Difference in reported device satisfaction on the Audio Processor Satisfaction Questionnaire (APSQ)</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Participants report subjective device satisfaction by marking on a visual analog scale from 0 to 10, with 0 being the minimum benefit and 10 being maximal benefit. A higher score is greater subjective satisfaction reported by the participant. Scores obtained with the SONNETEAS will be compared to those obtained with the SONNET2EAS, programmed with Automatic Sound Management 3.0.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Difference in reported subjective benefit on the Speech Domain of the Speech, Spatial and Qualities of Hearing (SSQ)</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Participants report subjective device benefit when hearing speech in a variety of competing contexts by marking on a visual analog scale from 0 to 10, with 0 being the minimum benefit and 10 being maximal benefit. A higher score is greater subjective benefit reported by the participant. Scores obtained with the SONNETEAS will be compared to those obtained with the SONNET2EAS, programmed with Automatic Sound Management 3.0.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Difference in reported subjective benefit on the Spatial Domain of the Speech, Spatial and Qualities of Hearing (SSQ)</measure>
    <time_frame>2 Years</time_frame>
    <description>Participants reported subjective device benefit for the directional, distance, and movement components of spatial hearing by marking on a visual analog scale from 0 to 10, with 0 being the minimum benefit and 10 being maximal benefit. A higher score is greater subjective benefit reported by the participant. Scores obtained with the SONNETEAS will be compared to those obtained with the SONNET2EAS, programmed with Automatic Sound Management 3.0.</description>
  </primary_outcome>
  <primary_outcome>
    <measure>Difference in reported subjective benefit on the Qualities Domain of the Speech, Spatial and Qualities of Hearing (SSQ)</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Participants reported subjective device benefit in qualities of hearing (including ease of listening and the naturalness, clarity, and identifiability of different sounds) by marking on a visual analog scale from 0 to 10, with 0 being the minimum benefit and 10 being maximal benefit. A higher score is greater subjective benefit reported by the participant. Scores obtained with the SONNETEAS will be compared to those obtained with the SONNET2EAS, programmed with Automatic Sound Management 3.0.</description>
  </primary_outcome>
  <secondary_outcome>
    <measure>Difference in Consonant-Nucleus-Consonant (CNC) Words Scores between listening with SONNET2EAS and contralateral ear plugged/masked with Artificial Intelligence (AI) Mild and AI Off.</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Testing open-set word understanding. Recorded CNC Words lists will be presented to the participant. Resultant score is a percentage of words correct with a range of 0% to 100%. A higher score is better. Scores obtained with the SONNET2EAS AI Mild will be compared to those obtained with the SONNET2EAS AI Off, programmed with Automatic Sound Management 3.0.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Difference in Hearing-in-Noise-Test (HINT) sentences in diffuse noise Scores between listening with SONNET2EAS and contralateral ear plugged/masked with Artificial Intelligence (AI) Mild and AI Off.</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Testing open-set sentence understanding with background noise present. Recorded HINT Sentences will be presented to the participant. Resultant score is a percentage of words correct with a range of 0% to 100%. A higher score is better. Scores obtained with the SONNET2EAS AI Mild will be compared to those obtained with the SONNET2EAS AI Off, programmed with Automatic Sound Management 3.0.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Difference in Consonant-Nucleus-Consonant (CNC) Words Scores between listening with SONNET2EAS and contralateral ear with Artificial Intelligence (AI) Mild and AI Off.</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Testing open-set word understanding. Recorded CNC Words lists will be presented to the participant. Resultant score is a percentage of words correct with a range of 0% to 100%. A higher score is better. Scores obtained with the SONNET2EAS AI Mild will be compared to those obtained with the SONNET2EAS AI Off, programmed with Automatic Sound Management 3.0.</description>
  </secondary_outcome>
  <secondary_outcome>
    <measure>Difference in Hearing-in-Noise-Test (HINT) sentences in diffuse noise Scores between listening with SONNET2EAS and contralateral ear with Artificial Intelligence (AI) Mild and AI Off.</measure>
    <time_frame>Up to 2 months after enrollment</time_frame>
    <description>Testing open-set sentence understanding with background noise present. Recorded HINT Sentences will be presented to the participant. Resultant score is a percentage of words correct with a range of 0% to 100%. A higher score is better. Scores obtained with the SONNET2EAS AI Mild will be compared to those obtained with the SONNET2EAS AI Off, programmed with Automatic Sound Management 3.0.</description>
  </secondary_outcome>
  <number_of_arms>1</number_of_arms>
  <enrollment type="Actual">0</enrollment>
  <condition>Hearing Loss</condition>
  <condition>Hearing Disability</condition>
  <arm_group>
    <arm_group_label>Automatic Sound Management 3.0</arm_group_label>
    <arm_group_type>Experimental</arm_group_type>
    <description>Current SONNETEAS listeners, who meet the eligibility criteria, will be tested with their current listening configuration and also fit with a SONNET2EAS, programmed with Automatic Sound Management 3.0 (under the Investigational Device Exemption).</description>
  </arm_group>
  <intervention>
    <intervention_type>Device</intervention_type>
    <intervention_name>Automatic Sound Management 3.0</intervention_name>
    <description>The investigational front-end features include those within Automatic Sound Management 3.0 (i.e., Ambient Noise and Transient-Noise Reduction, and Adaptive Intelligence). Automatic Sound Management 3.0 will be accessed in the MAESTRO system software. The investigational front-end features within Automatic Sound Management 3.0 will be programmed in the SONNET2EAS processor.</description>
    <arm_group_label>Automatic Sound Management 3.0</arm_group_label>
  </intervention>
  <eligibility>
    <criteria>
      <textblock>
        Inclusion Criteria:&#xD;
&#xD;
          -  Adult (≥18 years at date of enrollment/initial evaluation)&#xD;
&#xD;
          -  MED-EL Cochlear Implant System recipient&#xD;
&#xD;
          -  Unilateral cochlear implant recipient&#xD;
&#xD;
          -  Unaided threshold of ≤65 decibels (dB) Hearing Level (HL) at 125 Hz in implanted ear&#xD;
&#xD;
          -  Six months or greater of SONNETEAS listening experience&#xD;
&#xD;
          -  Consistent device user, as deemed by research team&#xD;
&#xD;
          -  Minimum of 10 enabled electrodes&#xD;
&#xD;
          -  Consonant Nucleus Consonant (CNC) word score of ≥40% with SONNETEAS processor and&#xD;
             contralateral ear plugged/masked&#xD;
&#xD;
          -  Native English speaker (as all materials are written or spoken in English)&#xD;
&#xD;
        Exclusion Criteria:&#xD;
&#xD;
          -  Unaided pure tone average (500, 1000, 2000 Hz) ≤60 dB HL in the contralateral&#xD;
             (non-implanted) ear&#xD;
&#xD;
          -  Hearing technology other than a conventional hearing aid in the contralateral ear&#xD;
&#xD;
          -  Unwilling, unable, or geographic limitations to participate in study procedures&#xD;
&#xD;
          -  Unwilling to complete datalogging with the processor&#xD;
      </textblock>
    </criteria>
    <gender>All</gender>
    <minimum_age>18 Years</minimum_age>
    <maximum_age>99 Years</maximum_age>
    <healthy_volunteers>Accepts Healthy Volunteers</healthy_volunteers>
  </eligibility>
  <overall_official>
    <last_name>Margaret T Dillon, AuD</last_name>
    <role>Principal Investigator</role>
    <affiliation>University of North Carolina, Chapel Hill</affiliation>
  </overall_official>
  <location>
    <facility>
      <name>University of North Carolina at Chapel Hill</name>
      <address>
        <city>Chapel Hill</city>
        <state>North Carolina</state>
        <zip>27599</zip>
        <country>United States</country>
      </address>
    </facility>
  </location>
  <location_countries>
    <country>United States</country>
  </location_countries>
  <reference>
    <citation>Adunka OF, Dillon MT, Adunka MC, King ER, Pillsbury HC, Buchman CA. Hearing preservation and speech perception outcomes with electric-acoustic stimulation after 12 months of listening experience. Laryngoscope. 2013 Oct;123(10):2509-15. doi: 10.1002/lary.23741. Epub 2013 Aug 5.</citation>
    <PMID>23918623</PMID>
  </reference>
  <reference>
    <citation>Billinger-Finke M, Bräcker T, Weber A, Amann E, Anderson I, Batsoulis C. Development and validation of the audio processor satisfaction questionnaire (APSQ) for hearing implant users. Int J Audiol. 2020 May;59(5):392-397. doi: 10.1080/14992027.2019.1697830. Epub 2020 Jan 16.</citation>
    <PMID>31944127</PMID>
  </reference>
  <reference>
    <citation>Gatehouse S, Noble W. The Speech, Spatial and Qualities of Hearing Scale (SSQ). Int J Audiol. 2004 Feb;43(2):85-99.</citation>
    <PMID>15035561</PMID>
  </reference>
  <reference>
    <citation>Gifford RH, Dorman MF. THE PSYCHOPHYSICS OF LOW-FREQUENCY ACOUSTIC HEARING IN ELECTRIC AND ACOUSTIC STIMULATION (EAS) AND BIMODAL PATIENTS. J Hear Sci. 2012 May 1;2(2):33-44.</citation>
    <PMID>24244874</PMID>
  </reference>
  <reference>
    <citation>Gifford RH, Grantham DW, Sheffield SW, Davis TJ, Dwyer R, Dorman MF. Localization and interaural time difference (ITD) thresholds for cochlear implant recipients with preserved acoustic hearing in the implanted ear. Hear Res. 2014 Jun;312:28-37. doi: 10.1016/j.heares.2014.02.007. Epub 2014 Mar 7.</citation>
    <PMID>24607490</PMID>
  </reference>
  <reference>
    <citation>Hagen R, Radeloff A, Stark T, Anderson I, Nopp P, Aschbacher E, Möltner A, Khajehnouri Y, Rak K. Microphone directionality and wind noise reduction enhance speech perception in users of the MED-EL SONNET audio processor. Cochlear Implants Int. 2020 Jan;21(1):53-65. doi: 10.1080/14670100.2019.1664529. Epub 2019 Sep 16.</citation>
    <PMID>31524107</PMID>
  </reference>
  <reference>
    <citation>PETERSON GE, LEHISTE I. Revised CNC lists for auditory tests. J Speech Hear Disord. 1962 Feb;27:62-70.</citation>
    <PMID>14485785</PMID>
  </reference>
  <reference>
    <citation>Pillsbury HC 3rd, Dillon MT, Buchman CA, Staecker H, Prentiss SM, Ruckenstein MJ, Bigelow DC, Telischi FF, Martinez DM, Runge CL, Friedland DR, Blevins NH, Larky JB, Alexiades G, Kaylie DM, Roland PS, Miyamoto RT, Backous DD, Warren FM, El-Kashlan HK, Slager HK, Reyes C, Racey AI, Adunka OF. Multicenter US Clinical Trial With an Electric-Acoustic Stimulation (EAS) System in Adults: Final Outcomes. Otol Neurotol. 2018 Mar;39(3):299-305. doi: 10.1097/MAO.0000000000001691.</citation>
    <PMID>29342054</PMID>
  </reference>
  <reference>
    <citation>Wolfe J, Neumann S, Marsh M, Schafer E, Lianos L, Gilden J, O'Neill L, Arkis P, Menapace C, Nel E, Jones M. Benefits of Adaptive Signal Processing in a Commercially Available Cochlear Implant Sound Processor. Otol Neurotol. 2015 Aug;36(7):1181-90. doi: 10.1097/MAO.0000000000000781.</citation>
    <PMID>26049314</PMID>
  </reference>
  <verification_date>August 2021</verification_date>
  <study_first_submitted>January 19, 2021</study_first_submitted>
  <study_first_submitted_qc>January 19, 2021</study_first_submitted_qc>
  <study_first_posted type="Actual">January 25, 2021</study_first_posted>
  <last_update_submitted>August 11, 2021</last_update_submitted>
  <last_update_submitted_qc>August 11, 2021</last_update_submitted_qc>
  <last_update_posted type="Actual">August 18, 2021</last_update_posted>
  <responsible_party>
    <responsible_party_type>Sponsor</responsible_party_type>
  </responsible_party>
  <keyword>Cochlear Implant</keyword>
  <keyword>Front End Processing</keyword>
  <keyword>Cochlear Implant Audio Processor</keyword>
  <condition_browse>
    <!-- CAUTION:  The following MeSH terms are assigned with an imperfect algorithm            -->
    <mesh_term>Hearing Loss</mesh_term>
  </condition_browse>
  <patient_data>
    <sharing_ipd>No</sharing_ipd>
  </patient_data>
  <!-- Results have not yet been posted for this study                                          -->
</clinical_study>

